# 7.1 Techniques for Selecting a Representative Subset of Data from a Stream

When working with massive data streams, it is often impractical or impossible to store and process every single element. Therefore, it is essential to have techniques for selecting a smaller, representative subset of the data (a sample) that can be used for analysis. The goal is to create a sample that accurately reflects the characteristics of the entire stream.

Here are some of the most common techniques for sampling from a data stream:

## 1. Reservoir Sampling

Reservoir sampling is a family of randomized algorithms for choosing a simple random sample of *k* items from a population of unknown size. It is particularly well-suited for data streams because it does not require knowing the total number of elements in the stream in advance.

*   **How it works (Algorithm R):**
    1.  The first *k* items from the stream are stored in a "reservoir."
    2.  For each subsequent item *i* (for *i* > *k*), a random integer *j* is generated between 1 and *i*.
    3.  If the random integer *j* is less than or equal to *k*, the *j*-th element in the reservoir is replaced with the new item *i*.
*   **Key Characteristic:** It ensures that every item in the stream has an equal probability of being included in the final sample.

## 2. Stratified Sampling

When a data stream is heterogeneous (i.e., it is composed of different sub-streams or "strata" with varying statistical properties), uniform sampling may not be effective. Stratified sampling addresses this by dividing the stream into distinct groups and sampling from each one.

*   **How it works:**
    1.  The stream is divided into different groups or categories (strata).
    2.  A sampling technique, such as reservoir sampling, is applied to each individual stratum.
*   **Key Characteristic:** It ensures that even small but important sub-groups are represented in the final sample, leading to more precise estimates.

## 3. Systematic Sampling

Systematic sampling involves selecting items at regular intervals. It is simple to implement but can be risky if the data has periodic patterns.

*   **How it works:**
    1.  A sampling interval *k* is chosen.
    2.  A random starting point from 1 to *k* is selected.
    3.  Every *k*-th item from the stream is selected, starting from the random start point.
*   **Key Risk:** If the data has a cyclical pattern that aligns with the sampling interval, the resulting sample will be biased and not representative.

## 4. Sliding Window Sampling

In many applications, recent data is more relevant than older data. Sliding window sampling focuses on maintaining a sample from only the most recent *N* items in the stream.

*   **How it works:**
    *   A window of the *N* most recent items is maintained.
    *   Sampling techniques, such as reservoir sampling, can be applied to just the elements within this window.
*   **Key Characteristic:** The sample is always representative of the most recent data, but it does not reflect the entire history of the stream.

## 5. Hash-Based Sampling

This technique uses a hash function to decide whether to include an item in the sample.

*   **How it works:**
    1.  A hash function is applied to each incoming item.
    2.  An item is selected if its hash value meets a predefined condition (e.g., the hash value is below a certain threshold).
*   **Key Advantage:** It is very fast and stateless. It also allows for coordinated sampling in a distributed environment; if different nodes use the same hash function and criterion, they can create consistent samples without communication.
